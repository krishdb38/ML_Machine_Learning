{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"datas/Iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>83</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>146</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0   66            6.7           3.1            4.4           1.4   \n",
       "1   16            5.7           4.4            1.5           0.4   \n",
       "2   83            5.8           2.7            3.9           1.2   \n",
       "3  118            7.7           3.8            6.7           2.2   \n",
       "4  146            6.7           3.0            5.2           2.3   \n",
       "\n",
       "           Species  \n",
       "0  Iris-versicolor  \n",
       "1      Iris-setosa  \n",
       "2  Iris-versicolor  \n",
       "3   Iris-virginica  \n",
       "4   Iris-virginica  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#suffling the dataset is better for both separating the dataset into train/test/validation and for avoiding overfitting\n",
    "iris =iris.sample(frac=1).reset_index(drop=True)\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to grab the data (the information on each sample) from the pandas array and put it into a nice numpy one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm',\n",
       "       'Species'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.7, 3.1, 4.4, 1.4],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [6.7, 3. , 5.2, 2.3]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = iris[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "x = np.array(x)\n",
    "x[:5]\n",
    "#Converting to Metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "one_hot_encoder  = OneHotEncoder(sparse=False)\n",
    "y = iris.Species\n",
    "y = one_hot_encoder.fit_transform(np.array(y).reshape(-1,1))\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will split our dataset into train/test using sklearn. initially the data will be split into train/test and then the \n",
    "#the training data will be further split into  train/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are going to build a simple neural network that supports multiple layers and validation . The main function is NeuralNetwork\n",
    "#which will train the nerwork for the specified number of epochs.\n",
    "#At first, the weights of the nerwork will get randomly initialized by InitializeWeights\n",
    "#Then, in each epoc , the weights will be updated by Train and finally, every 20 epochs accuracy both for the training and \n",
    "#Validation sets will be printed the Accuracy Function.\n",
    "#As input the function receives the following;\n",
    "\n",
    "#x-train , y_train : The training data and target Values\n",
    "#x_val , y_val : The Validation data and target values. These are optional parameters\n",
    "#epochs : Number of epochs. Defaults at 10\n",
    "#nodes A list of integers. Each integers . Each integer  denotes the number of nodes in each layer . The length of this list denotes\n",
    "#the number of layers\n",
    "#lr : The learning rate of the back-propagation training algorithm . Default at 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuralNetwork(x_train, y_train, x_val = None , y_val = None , epoch = 10, nodes=[], lr =0.15):\n",
    "    hidden_layers = len(nodes)-1\n",
    "    \n",
    "    weights = InitializeWeights(nodes)\n",
    "    \n",
    "    for epoch in range(1,epochs+1):\n",
    "        weights = Train(x_train, y_train, lr, weights)\n",
    "        \n",
    "        if (epoch %20 ==0):\n",
    "            print(\"Epoch {}\".format(epoch))\n",
    "            print(\"Training Accuracy:{}\".format(Accuracy(x_train, y_train, weights)))\n",
    "            \n",
    "            if x_val.any():\n",
    "                print(\"Validation Accuracy:{}\". format(Accuracy(x_val,y_val,weights)))\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InitializeWeights(nodes):\n",
    "    \"\"\"Initialize weights with random values in [-1, 1] (including bias)\"\"\"\n",
    "    layers, weights = len(nodes), []\n",
    "    \n",
    "    for i in range(1, layers):\n",
    "        w = [[np.random.uniform(-1, 1) for k in range(nodes[i-1] + 1)]\n",
    "              for j in range(nodes[i])]\n",
    "        weights.append(np.matrix(w))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the weights of the network at hand, we want to continuously adjust them actross the epochs so that (hopefully ) our network becomes more accurate. The training of the weights is accomplished via the popular (Forward) Back-Propagation algorithm. In this technique , the input first passes through the whole network and the output is calculated. Then, according to the error of this output, the weights of the network are updated from last to first. The error is propagated backwards, hence the name of the titular algorithm. Lets get into more detail about these two steps:\n",
    "### Forward Propagation \n",
    "* Each layer receives an input and computes an output.The output is computed by first calculating the dot product between the input and the weights of the layer and then passing this dot product through an activation function (in this case, the sigmoid function)\n",
    "* The output of each layer is the input of the next\n",
    "* The input of the first layer is the feature vector.\n",
    "* The output of the final layer is the prediction of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ForwardPropagation(x,weights, layers): #'\n",
    "    activations , layer_input = [x],x\n",
    "    \n",
    "    for j in range(layers):\n",
    "        activation = Sigmoid(np.dot(layer_input, weights[j].T))\n",
    "        activations.append(activation)\n",
    "        layer_input = np.append(1, activation ) # Augment with bias\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Calculate error at final output.\n",
    "* Propagate error backwards through the layers and perform corrections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BackPropagation(y, activations, weights, layers):\n",
    "    outputFinal=activations[-1]\n",
    "    error = np.matrix(y-outputFinal) #Error at output\n",
    "    \n",
    "    for j in range(layers , 0 , -1):\n",
    "        currActivation = activations[j]\n",
    "        \n",
    "        if (j>1):\n",
    "            # Augment Previous Activation\n",
    "            prevActivation = np.append(1,activations[j-1])\n",
    "        else:\n",
    "            #First hidden layer , PrevActivation is input (without bias)\n",
    "            prevActivation = activations[0]\n",
    "            \n",
    "        delta = np.multiply(error, SigmoidDerivative(currActivation))\n",
    "        weights[j-1] += lr* np.multiply(delta.T , prevActivation)\n",
    "        \n",
    "        w = np.delete(weights[j-1],[0], axis =1) #Remove bias from weights\n",
    "        error = np.dot(delta,w)  #Calculate error for currrent layer\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Our implementaion we will pass each sample of our dataset through the network performing first the forward pass and then the weight updating via the back-propagation algorithm. Finally, the newly calculated weights will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(x,y,lr,weights):\n",
    "    layers = len(weights)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        x,y = x[i], y[i]\n",
    "        x = np.matrix(np.append(1,x)) #Augment feature Vector\n",
    "        \n",
    "        activations = ForwardPropagation(x,weights, layers)\n",
    "        weights = BackPropagation(y, activations , weights, layers)\n",
    "        \n",
    "    return weights\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Networks need an activation function to pass the dot of each layer through to get the final output (as well as to get to the delta in back-propagation). \n",
    "In this tutorial, we will use the sigmoid function and its derivative . Other activation  functions are available , like the famous ReLU. Also , sometimes layer don't use the sam eactivation function, and there are times where the output doesn't have an activation function at all (for example, in the case of regression )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def SigmoidDerivative(x):\n",
    "    return np.multiply(x,1-x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we want to make a prediction for an item, we need to first pass it thorough network. The output of the network (in the case of three different classes, as in the iris problem ) will be in the form [x,y,z]  where x,y,z are real numbers in the range[0,1]. The higher the valueof an element, the more confident the network is that it is the correct class. We need to convert this output to the proper one-hot  format we mentioned earlier. Thus , we will take the largest of the outputs and set the corresponding index to 1, while the rest are set to 0. This means the predicted class is the one the network is most confident in  (ie. the greatest value.\n",
    "\n",
    "So, a prediction involves the forward propagation  and the conversion of the output to one-hot encoding, with the 1 denoting the predicted class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict(item, weights):\n",
    "    layers = len(weights)\n",
    "    item = np.append(1,item) #Augment feature Vector\n",
    "\n",
    "    ## _Forward Propagation_ ##\n",
    "    activations = ForwardPropagations(item, weights, layers)\n",
    "    \n",
    "    outputFinal = activations[-1].A1\n",
    "    index = FindMaxActivation(outputFinal)\n",
    "    \n",
    "    #Initalize prediction Vector to Zeros\n",
    "    y  = [ 0 for i in range(len(outputFinal))]\n",
    "    y[index] = 1 #set guessed class to 1\n",
    "    \n",
    "    return y  #Return Prediction Vector\n",
    "\n",
    "def FindMaxActivation(output):\n",
    "    \"\"\" Find max activation in Output \"\"\"\n",
    "    m, index = output[o],0\n",
    "    \n",
    "    for i in range(1, len(output)):\n",
    "        if (output[i]>m):\n",
    "            m, index = output[i],i\n",
    "            \n",
    "    return index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we need a way to evaluate our network. For this, we will write the Accuracy function which given the computed weights, predicts the class of each object in its input and checks it against the actual class, returning the percentage of correct predictions . \n",
    "Instead of the percentile accuracy, other accuracy metrics  can be employed, but for this tutorial this sample method will do "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(x,y, weights):\n",
    "    \"\"\" Run set through network, find overall accuracy \"\"\"\n",
    "    \n",
    "    correct = 0\n",
    "    for i in range(len(x)):\n",
    "        x,y= x[i] , list(y[i]) \n",
    "        guess = Predict(x,weights)\n",
    "        \n",
    "        if (y == guess):\n",
    "            #guessed Correctly \n",
    "            correct += 1\n",
    "            \n",
    "        return correct / len(x) #Percented guessed Corrected "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now completed our implementation and we can check teh results! Below we build a network by passing to the main function(Neural Network) the training/ Validation sets, the number of epochs, the learning rate and the number of nodes in each layer.\n",
    "During the training, after each 20th epoch, the accuracy of the network on the training and validation sets will be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-d181d3884438>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlayers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Number of nodes in layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.15\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-f3e859615808>\u001b[0m in \u001b[0;36mNeuralNetwork\u001b[1;34m(x_train, y_train, x_val, y_val, epoch, nodes, lr)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;36m20\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-679e89c2160f>\u001b[0m in \u001b[0;36mTrain\u001b[1;34m(x, y, lr, weights)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Augment feature Vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "f = len(x[0]) #Number of Features\n",
    "o = len(y[0]) #Number of outputs / classes\n",
    "\n",
    "layers = [f,5,10, o] #Number of nodes in layers\n",
    "lr , epochs = 0.15 , 100\n",
    "weights = NeuralNetwork(x_train , y_train , x_val ,y_val, epoch = epochs , nodes = layers , lr = lr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
