{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common metrics used for classifications\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recal \n",
    "- F1 Score\n",
    "- Area under the ROC (Receiver Operating Characteristic) curve or simply AUC(AUC)\n",
    "- Log loss\n",
    "- Precision at k (P@K)\n",
    "- Average precision at k (AP@k)\n",
    "- Mean average precision at k (MAP@k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common  metrics used for Regression\n",
    "- Mean Absolute Error (MAE)\n",
    "- Mean Squared error (MSE)\n",
    "- Root mean squared error (RMSE)\n",
    "- Root mean squared logarithmic error (RMSLE)\n",
    "- Mean absolute percentage error (MAPE)\n",
    "- R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## you must know which metrics where to use !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy \n",
    "- One of the most straightforward metrics used in machine learning.\n",
    "- It defines how accurate your model is.\n",
    "\n",
    "**python code for calculating accuracy is quite simple**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T00:52:43.368812Z",
     "start_time": "2021-01-11T00:52:43.365811Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate accuracy.\n",
    "    : param y_true : list of true values\n",
    "    : param y_pred : list of predicted values\n",
    "    : return : accuracy score , by dividing total true predicted by total\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize a simple counter for correct predictions\n",
    "    correct_counter = 0\n",
    "    \n",
    "    # loop over all elements of y_true\n",
    "    # and y_pred \"together\"\n",
    "    \n",
    "    for yt, yp in zip (y_true, y_pred):\n",
    "        if yt == yp:\n",
    "            # if predictions is equal to truth, increase the counter \n",
    "            correct_counter += 1\n",
    "    # return accuracy\n",
    "    # which is the correct predictions over the number of samples\n",
    "    return correct_counter / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T00:54:12.508794Z",
     "start_time": "2021-01-11T00:54:12.501799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time accuracy([1,2,3,4],[1,2,3,5])\n",
    "# Very small to compare time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T00:54:22.212574Z",
     "start_time": "2021-01-11T00:54:22.206575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "%time metrics.accuracy_score([1,2,3,4],[1,2,3,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T01:23:10.040808Z",
     "start_time": "2021-01-11T01:23:10.038808Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assume Positive Result class is 1 \n",
    "# Negative class is 0\n",
    "# Used Only for Binary Classification (Positive and Negative)\n",
    "# Generally Positive having some kind of problems or disease "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True Positive(TP) \n",
    "if you prediction is positive and the actual sample is positive\n",
    "#### True Negative (TN):\n",
    "If you predict Negative and the actual sample is Negative\n",
    "\n",
    "#### False Positive(FP):\n",
    "You predict Positive which is Negative\n",
    "#### False Negative(FN)\n",
    "You predicted Negative which is Positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True_Positive(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T01:12:52.322518Z",
     "start_time": "2021-01-11T01:12:52.318530Z"
    }
   },
   "outputs": [],
   "source": [
    "def true_positive(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate True Positives.\n",
    "    : param y_true : list of true valus\n",
    "    : param y_pred : list of predicted values\n",
    "    : return : number of true positives\n",
    "    \"\"\"\n",
    "    # initialize \n",
    "    tp = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        # 1 is True and input is 1 and 0 only \n",
    "        if yt == 1 and yp == 1 :\n",
    "            tp += 1\n",
    "    return tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T01:12:57.255554Z",
     "start_time": "2021-01-11T01:12:57.251581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_positive([1,0,1,0,1,0,1,0],[1,1,0,1,0,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## True Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T01:15:19.202699Z",
     "start_time": "2021-01-11T01:15:19.198700Z"
    }
   },
   "outputs": [],
   "source": [
    "def true_negative(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate True Negatives\n",
    "    : param y_true : list of true values\n",
    "    : param y_pred : list of predicted values\n",
    "    : return : number of true negatives\n",
    "    \"\"\"\n",
    "    # 1 is True and 0 is False\n",
    "    tn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 0:\n",
    "            tn += 1\n",
    "    return tn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T01:16:04.475607Z",
     "start_time": "2021-01-11T01:16:04.471608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_negative([1,0,1,0,1,0,1,0],[1,1,0,1,0,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T01:34:38.230797Z",
     "start_time": "2021-01-11T01:34:38.215170Z"
    }
   },
   "outputs": [],
   "source": [
    "def false_positive(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate False Positives\n",
    "    : param y_true : list of true values\n",
    "    : param y_pred : list of predicted values\n",
    "    : return : Number of False Positive\n",
    "    \"\"\"\n",
    "    fp = 0 \n",
    "    for yt , yp in zip (y_true, y_pred):\n",
    "        if yt == 0 and yp == 1:\n",
    "            fp += 1\n",
    "    return fp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T01:19:20.539674Z",
     "start_time": "2021-01-11T01:19:20.534676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positive([1,0,1,0,1,0,1,0],[1,1,0,1,0,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T01:31:30.467278Z",
     "start_time": "2021-01-11T01:31:30.463249Z"
    }
   },
   "outputs": [],
   "source": [
    "def false_negative(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate False Negatives\n",
    "    : param y_true : list of true values \n",
    "    : param y_pred : list of predicted values\n",
    "    : return : Number of false negatives\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize\n",
    "    fn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 0:\n",
    "            fn += 1\n",
    "    return fn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T01:31:40.757676Z",
     "start_time": "2021-01-11T01:31:40.751676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negative([1,0,1,0,1,0,1,0],[1,1,0,1,0,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T01:29:02.586146Z",
     "start_time": "2021-01-11T01:29:02.584145Z"
    }
   },
   "outputs": [],
   "source": [
    "# We can define accuracy using the terms described above,\n",
    "# We can write\n",
    "# Accuracy Score = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "# We can now quickly implement accuracy score using TP, TN, FP and FN in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T01:34:43.546847Z",
     "start_time": "2021-01-11T01:34:43.542845Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy_v2(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate accuracy using tp / tn / fp / fn\n",
    "    : param y_true : list of true values\n",
    "    : param y_pred : list of predicted values\n",
    "    : return : accuracy score\n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    \n",
    "    accuracy_score = (tp + tn ) / (tp + fp + fn + tn)\n",
    "    \n",
    "    return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T01:34:45.147155Z",
     "start_time": "2021-01-11T01:34:45.144141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.625\n",
      "0.625\n"
     ]
    }
   ],
   "source": [
    "# lets test \n",
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]\n",
    "print(accuracy(l1, l2))\n",
    "print(accuracy_v2(l1, l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "**TP/ (TP + FP )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T01:38:30.822462Z",
     "start_time": "2021-01-11T01:38:30.818437Z"
    }
   },
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate precision.\n",
    "    : param y_true : list of true values\n",
    "    : param y_pred : list of predicted values\n",
    "    : return : precision score\n",
    "    \n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    precision = tp / (tp + fp)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-11T01:38:42.307444Z",
     "start_time": "2021-01-11T01:38:42.303440Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to calculate Re call\n",
    "    : Param y_true : list of true values\n",
    "    : Param y_pred : list of predicted values\n",
    "    : return : recall score\n",
    "    \n",
    "    \"\"\"\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    recall = tp / (tp + fn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
